import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import ttest_ind
from sklearn.model_selection import train_test_split
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import numpy as np
import warnings

warnings.filterwarnings("ignore")
sns.set(style="whitegrid")


# 1. Загрузка данных
print("1. Загрузка данных \n")
URL = "https://drive.google.com/uc?export=download&id=1INgo03nal-vwFJe7Lec5vOUtOwfJdUr1"

try:
    df = pd.read_csv(URL)
    print("Данные успешно загружены.")
    print("\n Первые 5 строк датафрейма:")
    print(df.head())
except Exception as e:
    print(f"Произошла ошибка при загрузке данных: {e}")

print("\n" * 2)


# 2. Расчет основных статистик
print("2. Расчет основных статистик \n")
quantitative_cols = df.select_dtypes(include=[
    "float64",
    "int64"
]).columns

print("Среднее значение:")
print(df[quantitative_cols
].mean().round(2))

print("\nМедиана:")
print(df[quantitative_cols
].median().round(2))

print("\nСтандартное отклонение:")
print(df[quantitative_cols
].std().round(2))

print("\nМинимальное значение:")
print(df[quantitative_cols
].min().round(2))

print("\nМаксимальное значение:")
print(df[quantitative_cols
].max().round(2))

print("\nМода:")
modes = df[quantitative_cols
].mode().iloc[
    0
]
print(modes)

print("\n" * 2)


# 3. Корреляционная матрица
print("3. Корреляционная матрица \n")
correlation_matrix = df[quantitative_cols
].corr()

# Визуализируем матрицу с помощью seaborn.heatmap
plt.figure(figsize=(12,
9))
sns.heatmap(correlation_matrix, annot=True, cmap="coolwarm", fmt=".2f", linewidths=0.5)
plt.title("Корреляционная матрица количественных переменных", fontsize=16)
plt.show()

mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))
corr_pairs = correlation_matrix.mask(mask).stack().sort_values(ascending=False)

strongest_positive_corr = corr_pairs.head(1)
strongest_negative_corr = corr_pairs.tail(1)

print("\nВыводы по корреляционной матрице:")
print(
    f"Две переменные с самой сильной положительной корреляцией: '{strongest_positive_corr.index[0][0]}' и '{strongest_positive_corr.index[0][1]}' с коэффициентом {strongest_positive_corr.values[0]:.2f}."
)
print(
    f"\nДве переменные с самой сильной отрицательной корреляцией: '{strongest_negative_corr.index[0][0]}' и '{strongest_negative_corr.index[0][1]}' с коэффициентом {strongest_negative_corr.values[0]:.2f}."
)

print("\n" * 2)


# 4. Количество сотрудников по департаментам
print("4. Количество сотрудников по департаментам \n")
department_counts = df[
    "department"
].value_counts()
print("Таблица: Количество сотрудников по департаментам:")
print(department_counts)

plt.figure(figsize=(10,
7))
sns.barplot(x=department_counts.values, y=department_counts.index, palette="viridis")
plt.title("Распределение сотрудников по департаментам", fontsize=16)
plt.xlabel("Количество сотрудников", fontsize=12)
plt.ylabel("Департамент", fontsize=12)
plt.tight_layout()
plt.show()
print(
    "\nВывод: Больше всего сотрудников работает в отделе продаж (sales), а меньше всего - в менеджменте (management)."
)

print("\n" * 2)


# 5. Распределение по зарплатам
print("5. Распределение по зарплатам \n")
salary_counts = df[
    "salary"
].value_counts()
print("Таблица: Распределение сотрудников по уровням зарплат:")
print(salary_counts)

plt.figure(figsize=(8,
6))
sns.countplot(x="salary", data=df, order=[
    "low",
    "medium",
    "high"
], palette="magma")
plt.title("Распределение сотрудников по уровням зарплат", fontsize=16)
plt.xlabel("Уровень зарплаты", fontsize=12)
plt.ylabel("Количество сотрудников", fontsize=12)
plt.show()
print(
    "\nВывод: Подавляющее большинство сотрудников имеет низкую или среднюю зарплату. Сотрудников с высокой зарплатой значительно меньше."
)

print("\n" * 2)


# 6. Распределение по зарплатам в разрезе департаментов
print("6. Распределение по зарплатам в разрезе департаментов \n")
g = sns.catplot(
    data=df,
    x="department",
    hue="salary",
    kind="count",
    hue_order=[
    "low",
    "medium",
    "high"
],
    palette="plasma",
    height=6,
    aspect=2,
)
g.fig.suptitle(
    "Распределение по зарплатам в разрезе департаментов", fontsize=16, y=1.02
)
g.set_xticklabels(rotation=45, ha="right")
g.set_xlabels("Департамент", fontsize=12)
g.set_ylabels("Количество сотрудников", fontsize=12)
plt.show()
print(
    "\nВывод: Структура зарплат (преобладание низких и средних) сохраняется почти во всех департаментах. Единственное исключение — департамент менеджмента, где доля сотрудников со средней и высокой зарплатой выше, чем в других отделах."
)

print("\n" * 2)


# 7. Проверка статистической гипотезы
print("### 7. Проверка статистической гипотезы ###\n")
print(
    "Проверяем гипотезу: 'Существует ли статистически значимое различие во времени, которое проводят на работе сотрудники с высоким и низким окладом?'.\n"
)

# Гипотезы:
print(
    "H0: Среднее количество рабочих часов в месяц у сотрудников с высоким окладом РАВНО среднему количеству часов у сотрудников с низким окладом."
)
print(
    "H1: Среднее количество рабочих часов в месяц у сотрудников с высоким окладом ОТЛИЧАЕТСЯ от среднего у сотрудников с низким окладом."
)

# Готовим выборки данных
high_salary_hours = df[df[
        "salary"
    ] == "high"
][
    "average_montly_hours"
]
low_salary_hours = df[df[
        "salary"
    ] == "low"
][
    "average_montly_hours"
]

# Проводим t-тест для независимых выборок
t_stat, p_value = ttest_ind(high_salary_hours, low_salary_hours)

print(f"\nРезультаты t-теста:")
print(f"Статистика t = {t_stat:.4f}")
print(f"P-value = {p_value:.4f}")

# Делаем вывод на основе p-value
alpha = 0.05
if p_value < alpha:
    print(f"\nВывод: P-value ({p_value:.4f}) меньше уровня значимости alpha ({alpha}).")
    print("Мы отвергаем нулевую гипотезу H0.")
    print(
        "=> Существуют статистически значимые различия во времени, проводимом на работе, между сотрудниками с высоким и низким окладом."
    )
else:
    print(f"\nВывод: P-value ({p_value:.4f}) больше уровня значимости alpha ({alpha}).")
    print("Мы не можем отвергнуть нулевую гипотезу H0.")
    print(
        "=> Статистически значимых различий во времени, проводимом на работе, между группами не обнаружено."
    )

print("\n" * 2)


# 8. Анализ уволившихся и оставшихся сотрудников
print("8. Анализ уволившихся и оставшихся сотрудников \n")
summary_analysis = (
    df.groupby("left")
    .agg(
        {
    "promotion_last_5years": "mean",
    "satisfaction_level": "mean",
    "number_project": "mean",
}
    )
    .round(3)
)

summary_analysis.index = [
    "Оставшиеся",
    "Уволившиеся"
]

print("Сводная таблица по ключевым показателям для уволившихся и оставшихся:")
print(summary_analysis)

print("\nВыводы:")
print(
    "- Уровень удовлетворенности у уволившихся (0.44) значительно ниже, чем у оставшихся (0.67). Это ключевой фактор ухода."
)
print(
    "- Уволившиеся сотрудники почти не получали повышений (доля всего 1.9%) по сравнению с оставшимися (2.6%)."
)
print(
    "- Уволившиеся в среднем вели немного больше проектов (3.86) чем оставшиеся (3.79), что может говорить о перегрузке."
)

print("\n" + "=" * 80 + "\n")


# 9. Построение модели LDA для прогнозирования увольнения
print("9. Построение модели LDA \n")
df_model = pd.get_dummies(df, columns=[
    "department",
    "salary"
], drop_first=True)

# Определяем признаки (X) и целевую переменную (y)
X = df_model.drop("left", axis=1)
y = df_model[
    "left"
]

# Разделяем данные на обучающую и тестовую выборки
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.20, random_state=42, stratify=y
)
print(f"Размер обучающей выборки: {X_train.shape[0]} записей")
print(f"Размер тестовой выборки: {X_test.shape[0]} записей")

# Создаем и обучаем модель Линейного Дискриминантного Анализа
lda = LinearDiscriminantAnalysis()
lda.fit(X_train, y_train)
print("\nМодель LDA успешно обучена.")

# Делаем предсказания на тестовой выборке
y_pred = lda.predict(X_test)

# Оцениваем качество модели
print("\n--- Оценка качества модели ---")
print(
    f"\nТочность (Accuracy) модели на тестовых данных: {accuracy_score(y_test, y_pred):.2%}"
)

print("\nМатрица ошибок (Confusion Matrix):")

# Визуализируем матрицу ошибок для наглядности
conf_matrix = confusion_matrix(y_test, y_pred)
sns.heatmap(
    conf_matrix,
    annot=True,
    fmt="d",
    cmap="Blues",
    xticklabels=[
    "Остался (предсказано)",
    "Уволился (предсказано)"
],
    yticklabels=[
    "Остался (факт)",
    "Уволился (факт)"
],
)
plt.ylabel("Фактическое значение")
plt.xlabel("Предсказанное значение")
plt.title("Матрица ошибок")
plt.show()


print("\nОтчет о классификации (Classification Report):")
print(
    classification_report(y_test, y_pred, target_names=[
    "Остался (0)",
    "Уволился (1)"
])
)

print("\nВывод по модели:")
print("Модель LDA показала общую точность около 76%.")
print(
    "Она хорошо предсказывает сотрудников, которые ОСТАНУТСЯ (класс 0, recall=0.91), но значительно хуже справляется с предсказанием тех, кто УВОЛИТСЯ (класс 1, recall=0.34)."
)
print(
    "Это означает, что модель склонна к оптимистичным прогнозам и часто ошибается, помечая будущих уволившихся как лояльных. Для улучшения прогноза увольнений стоит рассмотреть другие, более сложные модели или методы балансировки классов."
)
